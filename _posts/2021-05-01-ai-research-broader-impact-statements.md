---
layout: paper
category: paper
title:  "Unpacking the Expressed Consequences of AI Research in Broader Impact Statements"
authors: "Priyanka Nanayakkara, Jessica Hullman, Nicholas Diakopoulos"
venue: "AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society 2021"
thumb: "assets/images/paper-thumb-ai-research-broader-impact-statements.png"
banner: "assets/images/paper-banner-ai-research-broader-impact-statements.png"
caption: "Prevalence of types of impacts written about in our sample of NeurIPS 2020 broader impact statements. The graphic originally appeared in a Technically Social blog post about the paper."
pdf: "assets/papers/2021-ai-research-broader-impact-statements.pdf"
addtinoals:
  - blog: "https://medium.com/technically-social/heres-how-ai-researchers-are-thinking-about-the-societal-impacts-of-ai-b82fc3f29b4d"
---

<!-- abstract -->
The computer science research community and the broader public have become increasingly aware of negative consequences of algorithmic systems. In response, the top-tier Neural Information Processing Systems (NeurIPS) conference for machine learning and artificial intelligence research required that authors include a statement of broader impact to reflect on potential positive and negative consequences of their work. We present the results of a qualitative thematic analysis of a sample of statements written for the 2020 conference. The themes we identify broadly fall into categories related to how consequences are expressed (e.g., valence, specificity, uncertainty), areas of impacts expressed (e.g., bias, the environment, labor, privacy), and researchers’ recommendations for mitigating negative consequences in the future. In light of our results, we offer perspectives on how the broader impact statement can be implemented in future iterations to better align with potential goals.
